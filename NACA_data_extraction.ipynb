{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrie1-s/Chagas_analysis/blob/cnn/NACA_data_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Version: for_CNN_1.0.0"
      ],
      "metadata": {
        "id": "TqBDmjdCbnxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install neptune-notebooks"
      ],
      "metadata": {
        "id": "y0k1xG2ti1oM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!jupyter nbextension enable --py neptune-notebooks"
      ],
      "metadata": {
        "id": "8yxTrDqGjGzs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset"
      ],
      "metadata": {
        "id": "jlLzB6Op56lv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install neptune-client"
      ],
      "metadata": {
        "id": "fhVwekgxqsc2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F8eh0g-sXkih"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import pdb\n",
        "import gc\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4QvCEhyNXkik"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade pip\n",
        "!pip install mat73\n",
        "!pip install scikit-learn --upgrade\n",
        "!pip install scipy\n",
        "!pip install Bayesian-Optimization\n",
        "!pip install fpdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ht3zGO5eXkil"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import mat73\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import statistics as st\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8VgOb7rXkil",
        "outputId": "fadbca24-4d61-48d2-fdba-96100f68b1a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CNN_Chagas/Chagas/LSTM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37i9sIuGFQnb",
        "outputId": "ad672653-5e9b-4702-ae67-609396404915"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CNN_Chagas/Chagas/LSTM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import neptune.new as neptune\n",
        "\n",
        "run = neptune.init_run(\n",
        "    project=\"gabrie1-s/NACA-data-extraction\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1ODlmNWY4ZS0zNmUzLTQ3NWQtYmVkYy05ZmUyMDM4ZGQxMzkifQ==\",\n",
        "    description='''Aplicamos o NACA para eliminar batimentos ruidosos e\n",
        "    sinais cujo valor do S/R > 15.\n",
        "    Consideramos 10 batimentos por sinal.Adotamos o procedimento de shifting com shift = 2.\n",
        "    Retornamos os sinais dos batimentos extraídos pelo NACA, estes são levemente\n",
        "    diferentes dos batimentos do sinal original''',\n",
        "    source_files=[\"NACA_data_extraction.ipynb\"],\n",
        ")  # your credentials"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66rTpHvcqqKv",
        "outputId": "8bb1b91a-879b-4f83-dddf-7bd0095d37b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/gabrie1-s/NACA-data-extraction/e/NAC-18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd -"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06IsK5QsFNcg",
        "outputId": "93da5f26-8e99-407d-9afa-e5d12e6d0206"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run[\"code_version\"] = \"for_CNN_1.0.0\""
      ],
      "metadata": {
        "id": "O99CyUbObWT0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bmIw3q6tYG8w"
      },
      "outputs": [],
      "source": [
        "dataset = mat73.loadmat('/content/drive/MyDrive/CNN_Chagas/Chagas/data/Dataset_Raw.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YwFFdA1OXkim"
      },
      "outputs": [],
      "source": [
        "signals = list(dataset['Dataset_Raw'])\n",
        "\n",
        "output = []\n",
        "for i in range(0, len(signals)):\n",
        "    output.append(signals[i][-1])\n",
        "    signals[i] = np.delete(signals[i], [-1,-2])\n",
        "    # signals[i] = signals[i][0:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zEC5iinUXkin"
      },
      "outputs": [],
      "source": [
        "def discrete_ratio(ratio_set, n):\n",
        "    classes = list(range(1, n+1))\n",
        "    ratio = 1.0/n\n",
        "\n",
        "    for j in range(0, len(ratio_set)):\n",
        "        for i in range(0, n):\n",
        "            if ratio_set[j] > ratio*i and ratio_set[j] <= ratio*(i+1):\n",
        "                ratio_set[j] = int(classes[i])\n",
        "                break\n",
        "\n",
        "    return ratio_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UEAGpqBGXkio"
      },
      "outputs": [],
      "source": [
        "output = discrete_ratio(output, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-agT3nB6Xkio"
      },
      "outputs": [],
      "source": [
        "with open('Sinais_Chagas.txt') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "idx = []\n",
        "\n",
        "for i in range(0, len(lines)):\n",
        "  arq = lines[i][lines[i].find('FileName1 = '):lines[i].find('\\n')]\n",
        "  signal = lines[i][lines[i].find('Signals{'):lines[i].find('\\n')]\n",
        "  signal = signal[signal.find('{')+1 : signal.find('}')]\n",
        "\n",
        "  if arq != '':\n",
        "    idx.append(arq[13:-2])\n",
        "  if signal != '':\n",
        "     idx.append(signal)\n",
        "\n",
        "idx = idx[:-3]\n",
        "\n",
        "\n",
        "pairs = []\n",
        "for i in range(0, len(idx), 2):\n",
        "  val = [idx[i+1], idx[i]]\n",
        "  pairs.append(val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hZnHcurcXkip"
      },
      "outputs": [],
      "source": [
        "matriz_pontos = []\n",
        "for i in pairs:\n",
        "    url =  str(i[1]) + '_MatrizPontos.mat'\n",
        "    pontos = sio.loadmat(url)\n",
        "    matriz_pontos.append(pontos[\"Matriz_Pontos\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Kx_g7cydCGZQ"
      },
      "outputs": [],
      "source": [
        "peaks = []\n",
        "for sig in matriz_pontos:\n",
        "  line = []\n",
        "  for beat in sig:\n",
        "    line.append(beat[4])\n",
        "  peaks.append(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxlzFkyVMmQ4"
      },
      "source": [
        "## Butterworth filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0VNXnX5rMyPL"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "order = 2\n",
        "fs = 128  # Sampling frequency\n",
        "fc = 1  # Cutoff frequency\n",
        "b, a = butter(order, fc, btype='high', fs=fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "f0YqzZjHYZVS"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "\n",
        "for signal in signals:\n",
        "  filtered_signal = filtfilt(b, a, signal)\n",
        "  x.append(filtered_signal)\n",
        "\n",
        "signals = x\n",
        "del x, filtered_signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrjuautBNHuQ"
      },
      "source": [
        "## Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ORZy1u5CxMLM"
      },
      "outputs": [],
      "source": [
        "indexes = range(len(signals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KpiRuKcPC7_h"
      },
      "outputs": [],
      "source": [
        "m_rem, m_te, x_rem, x_te, p_rem, p_te, y_rem, y_te = train_test_split(matriz_pontos, signals, peaks, output, test_size=0.15, stratify=output, random_state=38)\n",
        "m_tr, m_va, x_tr, x_va, p_tr, p_va, y_tr, y_va = train_test_split(m_rem, x_rem, p_rem, y_rem, test_size=0.15, stratify=y_rem, random_state=38)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_-aVlTcgV9M"
      },
      "source": [
        "## Medium beats acquisition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WzPUEgOvATot"
      },
      "outputs": [],
      "source": [
        "def signals_med(array):\n",
        "    array_size = len(array[0])\n",
        "    array_qnt = len(array)\n",
        "    md_vector = []\n",
        "\n",
        "    for j in range(0, array_size):\n",
        "        aux = []\n",
        "\n",
        "        for i in range(0, array_qnt):\n",
        "            aux.append(array[i][j])\n",
        "\n",
        "        md_vector.append(st.median(aux))\n",
        "\n",
        "    return md_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Rf8NMyK89P8Q"
      },
      "outputs": [],
      "source": [
        "def shifting(signal, samples_position, beat_template, peaks):\n",
        "  samples = []\n",
        "  shift = 2\n",
        "  for p_index, p in enumerate(samples_position):\n",
        "    aux = []\n",
        "    for i in range(-1*shift, shift+1):\n",
        "      aux.append(mean_squared_error(beat_template, signal[p[0]+i:p[1]+i]))\n",
        "\n",
        "    M = aux.index(min(aux)) - shift\n",
        "    samples_position[p_index] = [p[0]+M, p[1]+M]\n",
        "    samples.append(signal[p[0]+M : p[1]+M])\n",
        "    peaks[p_index] += M\n",
        "\n",
        "\n",
        "  return samples_position, samples, peaks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kEhxJG3AAVKj"
      },
      "outputs": [],
      "source": [
        "def del_var(samples, samples_position, beat_template):\n",
        "\n",
        "    for idx, sample in enumerate(samples):\n",
        "        val = 0\n",
        "        for i in range (len(sample)):\n",
        "            val += (sample[i] - beat_template[i])**2\n",
        "\n",
        "        val /= len(sample)\n",
        "\n",
        "        if val > st.variance(beat_template):\n",
        "            samples.pop(idx)\n",
        "            samples_position.pop(idx)\n",
        "\n",
        "    return samples_position, samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7vkLXIGYGT3M"
      },
      "outputs": [],
      "source": [
        "def snr(beat_template, samples):\n",
        "  var = st.variance(beat_template)\n",
        "  noise = []\n",
        "\n",
        "  for sample in samples:\n",
        "    n = st.variance(np.subtract(beat_template, sample))\n",
        "    noise.append(n)\n",
        "\n",
        "  sr = var/st.median(noise)\n",
        "  return sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "xdvHNMeGAbAQ"
      },
      "outputs": [],
      "source": [
        "def window(signal, peaks):\n",
        "    #calculating L\n",
        "    peaks_difference = [peaks[i+1] - peaks[i] for i in range(len(peaks)-1)]\n",
        "    L = 1.1*st.median(peaks_difference)\n",
        "\n",
        "\n",
        "    #obtening beat samples\n",
        "    #samples position consists in an array of tuples. Each tuples contains the estimate begin and end of a beat\n",
        "    samples_position = []\n",
        "    samples = []\n",
        "\n",
        "    # pdb.set_trace()\n",
        "    for idx, p in enumerate(peaks):\n",
        "        samples.append(signal[p-math.floor(L/3) : p+math.ceil(2*L/3)])\n",
        "        samples_position.append([p-math.floor(L/3) , p+math.ceil(2*L/3)])\n",
        "\n",
        "    beat_template = signals_med(samples)\n",
        "    samples_position, samples, peaks = shifting(signal, samples_position, beat_template, peaks)\n",
        "    samples_position, samples = del_var(samples, samples_position, beat_template)\n",
        "    sr = snr(beat_template, samples)\n",
        "\n",
        "    return sr, samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "iHD3gG5eXkir"
      },
      "outputs": [],
      "source": [
        "del dataset, signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "cNQjNAYYXkis"
      },
      "outputs": [],
      "source": [
        "bps = 10\n",
        "thres = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "PWm_hAJ-K_uB"
      },
      "outputs": [],
      "source": [
        "def thres_test(signal, peaks, outputs, bps):\n",
        "  templates = []\n",
        "  y = []\n",
        "\n",
        "  for idx, p in enumerate(peaks):\n",
        "    sig_1 = []\n",
        "    for i in range(0, len(p)-bps, bps):\n",
        "        sr, samples = window(signal[idx], p[i:i+bps])\n",
        "\n",
        "        if sr > thres:\n",
        "          samples = np.concatenate(samples)\n",
        "          sig_1.append(samples)\n",
        "\n",
        "    if len(sig_1) > 0:\n",
        "      sig_1 = np.array(sig_1, dtype='object')\n",
        "      sig_1 = np.concatenate(sig_1)\n",
        "      templates.append(sig_1)\n",
        "      y.append(outputs[idx])\n",
        "\n",
        "  templates = np.array(templates)\n",
        "  # pdb.set_trace()\n",
        "\n",
        "  # arr_idxs = noise_rates.argsort()\n",
        "  # noise_rates = noise_rates[arr_idxs[::-1]]\n",
        "  # templates = templates[arr_idxs[::-1]]\n",
        "  # y = y[arr_idxs[::-1]]\n",
        "\n",
        "  return templates, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-RNmiubOkQx",
        "outputId": "14116e10-97de-4b98-a9f0-4c88552af9f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-3ccf8155a77f>:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  templates = np.array(templates)\n",
            "<ipython-input-47-3ccf8155a77f>:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  templates = np.array(templates)\n",
            "<ipython-input-47-3ccf8155a77f>:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  templates = np.array(templates)\n"
          ]
        }
      ],
      "source": [
        "x_tr, y_tr = thres_test(x_tr, p_tr, y_tr, bps)\n",
        "x_va, y_va = thres_test(x_va, p_va, y_va, bps)\n",
        "x_te, y_te = thres_test(x_te, p_te, y_te, bps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"dataset/x_tr.npy\", x_tr)\n",
        "np.save(\"dataset/x_va.npy\", x_va)\n",
        "np.save(\"dataset/x_te.npy\", x_te)\n",
        "\n",
        "np.save(\"dataset/y_tr.npy\", y_tr)\n",
        "np.save(\"dataset/y_va.npy\", y_va)\n",
        "np.save(\"dataset/y_te.npy\", y_te)"
      ],
      "metadata": {
        "id": "gd4GSjPjavmk"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run[\"data\"].upload_files(\"./dataset/*.npy\")"
      ],
      "metadata": {
        "id": "XVsFD2LboyAk"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.stop()"
      ],
      "metadata": {
        "id": "OrTi5DUNfOBH"
      },
      "execution_count": 52,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOVz5ytke2vVr14ioE+zDI+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}