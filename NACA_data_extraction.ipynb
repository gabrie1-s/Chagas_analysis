{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrie1-s/Chagas_analysis/blob/main/NACA_data_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Version: for_LSTM_1.0.0"
      ],
      "metadata": {
        "id": "TqBDmjdCbnxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install neptune-notebooks"
      ],
      "metadata": {
        "id": "y0k1xG2ti1oM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbextension enable --py neptune-notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yxTrDqGjGzs",
        "outputId": "454a1ab9-f10e-42e1-d8e3-a33a3315fc7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enabling notebook extension neptune-notebooks/neptune-notebook...\n",
            "Paths used for configuration of notebook: \n",
            "    \t/root/.jupyter/nbconfig/notebook.json\n",
            "Paths used for configuration of notebook: \n",
            "    \t\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n",
            "Paths used for configuration of notebook: \n",
            "    \t/root/.jupyter/nbconfig/notebook.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install neptune-client"
      ],
      "metadata": {
        "id": "fhVwekgxqsc2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CNN_Chagas/Chagas/LSTM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQfkAv69MQ4y",
        "outputId": "edf9db22-06b0-4b03-83f0-499ac4503307"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CNN_Chagas/Chagas/LSTM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import neptune.new as neptune\n",
        "\n",
        "run = neptune.init_run(\n",
        "    project=\"gabrie1-s/NACA-data-extraction\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1ODlmNWY4ZS0zNmUzLTQ3NWQtYmVkYy05ZmUyMDM4ZGQxMzkifQ==\",\n",
        "    description='''Aplicamos o NACA para fazer (apenas) o cálculo de S/R.\n",
        "    Consideramos 3 batimentos por sinal.Não foi adotado o procedimento de shifting.\n",
        "    Não usamos os batimentos extraídos pelo NACA, usamos os intervalos já fornecidos\n",
        "    no arquivo matri_pontos para extrair os sinais. A ideia é passarmos sinais ininterruptos\n",
        "    de uma sequência de 3 batimentos para uma rede LSTM.''',\n",
        "    source_files=[\"NACA_data_extraction.ipynb\"],\n",
        ")  # your credentials"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66rTpHvcqqKv",
        "outputId": "95ad040e-eaaa-47f8-f82b-bd9c71e5cdc9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/gabrie1-s/NACA-data-extraction/e/NAC-7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "F8eh0g-sXkih"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import pdb\n",
        "import gc\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4QvCEhyNXkik"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade pip\n",
        "!pip install mat73\n",
        "!pip install scikit-learn --upgrade\n",
        "!pip install scipy\n",
        "!pip install Bayesian-Optimization\n",
        "!pip install fpdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ht3zGO5eXkil"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import mat73\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import statistics as st\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8VgOb7rXkil",
        "outputId": "b9fd5cd9-f7bf-479e-c09b-4573509617f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bmIw3q6tYG8w"
      },
      "outputs": [],
      "source": [
        "dataset = mat73.loadmat('/content/drive/MyDrive/CNN_Chagas/Chagas/data/Dataset_Raw.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YwFFdA1OXkim"
      },
      "outputs": [],
      "source": [
        "signals = list(dataset['Dataset_Raw'])\n",
        "\n",
        "output = []\n",
        "for i in range(0, len(signals)):\n",
        "    output.append(signals[i][-1])\n",
        "    signals[i] = np.delete(signals[i], [-1,-2])\n",
        "    # signals[i] = signals[i][0:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zEC5iinUXkin"
      },
      "outputs": [],
      "source": [
        "def discrete_ratio(ratio_set, n):\n",
        "    classes = list(range(1, n+1))\n",
        "    ratio = 1.0/n\n",
        "\n",
        "    for j in range(0, len(ratio_set)):\n",
        "        for i in range(0, n):\n",
        "            if ratio_set[j] > ratio*i and ratio_set[j] <= ratio*(i+1):\n",
        "                ratio_set[j] = int(classes[i])\n",
        "                break\n",
        "\n",
        "    return ratio_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UEAGpqBGXkio"
      },
      "outputs": [],
      "source": [
        "output = discrete_ratio(output, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-agT3nB6Xkio"
      },
      "outputs": [],
      "source": [
        "with open('Sinais_Chagas.txt') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "idx = []\n",
        "\n",
        "for i in range(0, len(lines)):\n",
        "  arq = lines[i][lines[i].find('FileName1 = '):lines[i].find('\\n')]\n",
        "  signal = lines[i][lines[i].find('Signals{'):lines[i].find('\\n')]\n",
        "  signal = signal[signal.find('{')+1 : signal.find('}')]\n",
        "\n",
        "  if arq != '':\n",
        "    idx.append(arq[13:-2])\n",
        "  if signal != '':\n",
        "     idx.append(signal)\n",
        "\n",
        "idx = idx[:-3]\n",
        "\n",
        "\n",
        "pairs = []\n",
        "for i in range(0, len(idx), 2):\n",
        "  val = [idx[i+1], idx[i]]\n",
        "  pairs.append(val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hZnHcurcXkip"
      },
      "outputs": [],
      "source": [
        "matriz_pontos = []\n",
        "for i in pairs:\n",
        "    url =  str(i[1]) + '_MatrizPontos.mat'\n",
        "    pontos = sio.loadmat(url)\n",
        "    matriz_pontos.append(pontos[\"Matriz_Pontos\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Kx_g7cydCGZQ"
      },
      "outputs": [],
      "source": [
        "peaks = []\n",
        "for sig in matriz_pontos:\n",
        "  line = []\n",
        "  for beat in sig:\n",
        "    line.append(beat[4])\n",
        "  peaks.append(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxlzFkyVMmQ4"
      },
      "source": [
        "## Butterworth filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0VNXnX5rMyPL"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "order = 2\n",
        "fs = 128  # Sampling frequency\n",
        "fc = 1  # Cutoff frequency\n",
        "b, a = butter(order, fc, btype='high', fs=fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "f0YqzZjHYZVS"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "\n",
        "for signal in signals:\n",
        "  filtered_signal = filtfilt(b, a, signal)\n",
        "  x.append(filtered_signal)\n",
        "\n",
        "signals = x\n",
        "del x, filtered_signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrjuautBNHuQ"
      },
      "source": [
        "## Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ORZy1u5CxMLM"
      },
      "outputs": [],
      "source": [
        "indexes = range(len(signals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KpiRuKcPC7_h"
      },
      "outputs": [],
      "source": [
        "m_rem, m_te, x_rem, x_te, p_rem, p_te, y_rem, y_te = train_test_split(matriz_pontos, signals, peaks, output, test_size=0.15, stratify=output, random_state=38)\n",
        "m_tr, m_va, x_tr, x_va, p_tr, p_va, y_tr, y_va = train_test_split(m_rem, x_rem, p_rem, y_rem, test_size=0.15, stratify=y_rem, random_state=38)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_-aVlTcgV9M"
      },
      "source": [
        "## Medium beats acquisition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WzPUEgOvATot"
      },
      "outputs": [],
      "source": [
        "def signals_med(array):\n",
        "    array_size = len(array[0])\n",
        "    array_qnt = len(array)\n",
        "    md_vector = []\n",
        "\n",
        "    for j in range(0, array_size):\n",
        "        aux = []\n",
        "\n",
        "        for i in range(0, array_qnt):\n",
        "            aux.append(array[i][j])\n",
        "\n",
        "        md_vector.append(st.median(aux))\n",
        "\n",
        "    return md_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Rf8NMyK89P8Q"
      },
      "outputs": [],
      "source": [
        "def shifting(signal, samples_position, beat_template, peaks):\n",
        "  samples = []\n",
        "  shift = 10\n",
        "  for p_index, p in enumerate(samples_position):\n",
        "    aux = []\n",
        "    for i in range(-1*shift, shift+1):\n",
        "      aux.append(mean_squared_error(beat_template, signal[p[0]+i:p[1]+i]))\n",
        "\n",
        "    M = aux.index(min(aux)) - shift\n",
        "    samples_position[p_index] = [p[0]+M, p[1]+M]\n",
        "    samples.append(signal[p[0]+M : p[1]+M])\n",
        "    peaks[p_index] += M\n",
        "\n",
        "\n",
        "  return samples_position, samples, peaks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kEhxJG3AAVKj"
      },
      "outputs": [],
      "source": [
        "def del_var(samples, samples_position, beat_template):\n",
        "\n",
        "    for idx, sample in enumerate(samples):\n",
        "        val = 0\n",
        "        for i in range (len(sample)):\n",
        "            val += (sample[i] - beat_template[i])**2\n",
        "\n",
        "        val /= len(sample)\n",
        "\n",
        "        if val > st.variance(beat_template):\n",
        "            samples.pop(idx)\n",
        "            samples_position.pop(idx)\n",
        "\n",
        "    return samples_position, samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7vkLXIGYGT3M"
      },
      "outputs": [],
      "source": [
        "def snr(beat_template, samples):\n",
        "  var = st.variance(beat_template)\n",
        "  noise = []\n",
        "\n",
        "  for sample in samples:\n",
        "    n = st.variance(np.subtract(beat_template, sample))\n",
        "    noise.append(n)\n",
        "\n",
        "  sr = var/st.median(noise)\n",
        "  return sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xdvHNMeGAbAQ"
      },
      "outputs": [],
      "source": [
        "def window(signal, peaks):\n",
        "    #calculating L\n",
        "    peaks_difference = [peaks[i+1] - peaks[i] for i in range(len(peaks)-1)]\n",
        "    L = 1.1*st.median(peaks_difference)\n",
        "\n",
        "\n",
        "    #obtening beat samples\n",
        "    #samples position consists in an array of tuples. Each tuples contains the estimate begin and end of a beat\n",
        "    samples_position = []\n",
        "    samples = []\n",
        "\n",
        "    # pdb.set_trace()\n",
        "    for idx, p in enumerate(peaks):\n",
        "        samples.append(signal[p-math.floor(L/3) : p+math.ceil(2*L/3)])\n",
        "        samples_position.append([p-math.floor(L/3) , p+math.ceil(2*L/3)])\n",
        "\n",
        "    beat_template = signals_med(samples)\n",
        "    # samples_position, samples, peaks = shifting(signal, samples_position, beat_template, peaks)\n",
        "    # samples_position, samples = del_var(samples, beat_template)\n",
        "    sr = snr(beat_template, samples)\n",
        "\n",
        "    peaks = np.array(peaks)-(peaks[0]-math.floor(L/3))\n",
        "\n",
        "    return sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iHD3gG5eXkir"
      },
      "outputs": [],
      "source": [
        "del dataset, signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cNQjNAYYXkis"
      },
      "outputs": [],
      "source": [
        "bps = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PWm_hAJ-K_uB"
      },
      "outputs": [],
      "source": [
        "def thres_test(signal, peaks, mp, outputs, bps):\n",
        "  templates = []\n",
        "  noise_rates = []\n",
        "  y = []\n",
        "\n",
        "  # ps = []\n",
        "\n",
        "  for idx, p in enumerate(peaks):\n",
        "    for i in range(0, len(p)-bps, bps):\n",
        "        sr = window(signal[idx], p[i:i+bps])\n",
        "\n",
        "        ini = mp[idx][i][0]\n",
        "        end = mp[idx][i+bps-1][-1]\n",
        "        beats_t = signal[idx][ini:end]\n",
        "\n",
        "        templates.append(beats_t)\n",
        "        noise_rates.append(sr)\n",
        "        y.append(outputs[idx])\n",
        "        # ps.append(pk)\n",
        "\n",
        "  noise_rates = np.array(noise_rates)\n",
        "  templates = np.array(templates)\n",
        "  y = np.array(y)\n",
        "  # ps = np.array(ps)\n",
        "\n",
        "  arr_idxs = noise_rates.argsort()\n",
        "  noise_rates = noise_rates[arr_idxs[::-1]]\n",
        "  templates = templates[arr_idxs[::-1]]\n",
        "  y = y[arr_idxs[::-1]]\n",
        "  # ps = ps[arr_idxs[::-1]]\n",
        "\n",
        "  return noise_rates, templates, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-RNmiubOkQx",
        "outputId": "d0086cb9-0923-4ace-b8a3-81c267001980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-f839adc6eda3>:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  templates = np.array(templates)\n"
          ]
        }
      ],
      "source": [
        "sr_tr, x_tr, y_tr = thres_test(x_tr, p_tr, m_tr, y_tr, bps)\n",
        "sr_va, x_va, y_va = thres_test(x_va, p_va, m_va, y_va, bps)\n",
        "sr_te, x_te, y_te = thres_test(x_te, p_te, m_te, y_te, bps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"dataset/x_tr.npy\", x_tr)\n",
        "np.save(\"dataset/x_va.npy\", x_va)\n",
        "np.save(\"dataset/x_te.npy\", x_te)\n",
        "\n",
        "np.save(\"dataset/y_tr.npy\", y_tr)\n",
        "np.save(\"dataset/y_va.npy\", y_va)\n",
        "np.save(\"dataset/y_te.npy\", y_te)\n",
        "\n",
        "np.save(\"dataset/sr_tr.npy\", sr_tr)\n",
        "np.save(\"dataset/sr_va.npy\", sr_va)\n",
        "np.save(\"dataset/sr_te.npy\", sr_te)"
      ],
      "metadata": {
        "id": "gd4GSjPjavmk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run[\"dataset/v0.1\"].track_files(\"dataset\")"
      ],
      "metadata": {
        "id": "_uYSkAnK_mPK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run[\"code_version\"] = \"for_LSTM_1.0.0\""
      ],
      "metadata": {
        "id": "O99CyUbObWT0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrTi5DUNfOBH",
        "outputId": "2171fb59-f3d9-4b44-df9e-b5d3d5958ba1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "All 0 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/gabrie1-s/NACA-data-extraction/e/NAC-5/metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMDCEKLgEbK3"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize']=(20,5)\n",
        "size = 0\n",
        "\n",
        "for i in range(len(sr)):\n",
        "  if sr[i] > 15 and sr[i] < 20:\n",
        "    print(str(i) +\"____\"+str(sr[i]))\n",
        "    #plt.plot(templates[i], markevery=ps[i], marker='x', mec='red', mew=3)\n",
        "\n",
        "    plt.plot(templates[i])\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMbdE+fNVv41dqzlrmmhtbE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}